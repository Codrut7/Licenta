{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import keras\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LeakyReLU, BatchNormalization, Reshape, Flatten, Input, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Conv2DTranspose, GaussianNoise, InputLayer\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 0\n",
    "TRAINING_IMAGES_PATH = None\n",
    "RESULT_IMAGES_PATH = None\n",
    "EPOCHS = 0\n",
    "BATCH_SIZE = 0\n",
    "\n",
    "def read_settings():\n",
    "    global IMAGE_SIZE\n",
    "    global TRAINING_IMAGES_PATH\n",
    "    global RESULT_IMAGES_PATH\n",
    "    global EPOCHS\n",
    "    global BATCH_SIZE\n",
    "    f = open(os.path.abspath(\"settings.txt\"), \"r\")\n",
    "    line = f.readline()\n",
    "    TRAINING_IMAGES_PATH = line.split('=')[1].replace('\\n','')\n",
    "    line = f.readline()\n",
    "    RESULT_IMAGES_PATH = line.split('=')[1].replace('\\n','')\n",
    "    line = f.readline()\n",
    "    IMAGE_SIZE = int(line.split('=')[1].replace('\\n',''))\n",
    "    line = f.readline()\n",
    "    EPOCHS = int(line.split('=')[1].replace('\\n',''))\n",
    "    line = f.readline()\n",
    "    BATCH_SIZE = int(line.split('=')[1].replace('\\n', ''))\n",
    "\n",
    "read_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e120aedabfe4c72b3e3e8b7f7770d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4170), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SAMPLES = len(os.listdir(TRAINING_IMAGES_PATH))\n",
    "TRAINING_DATA = np.empty([TRAINING_SAMPLES, IMAGE_SIZE, IMAGE_SIZE, 3])\n",
    "\n",
    "def read_images():\n",
    "    iterator = 0\n",
    "    for file in tqdm_notebook(os.listdir(TRAINING_IMAGES_PATH)):\n",
    "        image = cv2.imread(TRAINING_IMAGES_PATH + file)\n",
    "        img = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        im_array = np.asarray(img) / 255\n",
    "        TRAINING_DATA[iterator] = im_array\n",
    "        iterator += 1\n",
    "        \n",
    "read_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8192)              827392    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 256)         3277056   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 16, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 32, 32, 128)       819328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 64, 64, 64)        204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 64, 64, 3)         4803      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 64, 3)         0         \n",
      "=================================================================\n",
      "Total params: 6,774,915\n",
      "Trainable params: 6,773,507\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_generator():\n",
    "    epsilon = 0.00001 # Small float added to variance to avoid dividing by zero in the BatchNorm layers.\n",
    "    noise_shape = (100,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(4*4*512, activation='linear', input_shape=(100,)))\n",
    "    model.add(Reshape((4, 4, 512)))\n",
    "\n",
    "    model.add(Conv2DTranspose(256, kernel_size=[5,5], strides=[2,2], padding=\"same\",\n",
    "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2DTranspose(256, kernel_size=[5,5], strides=[2,2], padding=\"same\",\n",
    "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, kernel_size=[5,5], strides=[2,2], padding=\"same\",\n",
    "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2DTranspose(64, kernel_size=[5,5], strides=[2,2], padding=\"same\",\n",
    "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
    "    model.add(BatchNormalization(momentum=0.9, epsilon=epsilon))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2DTranspose(3, kernel_size=[5,5], strides=[1,1], padding=\"same\",\n",
    "                              kernel_initializer= keras.initializers.TruncatedNormal(stddev=0.02)))\n",
    "    # Standard activation for the generator of a GAN\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=(100,))\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)\n",
    "\n",
    "generator = create_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_1 (GaussianNo (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 394,433\n",
      "Trainable params: 393,473\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_discriminator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3)))\n",
    "    model.add(GaussianNoise(0.2))\n",
    "    model.add(Conv2D(32, (3, 3), strides=[2,2],padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Conv2D(64, (3, 3),strides=[2,2], kernel_initializer='he_uniform', padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Conv2D(128, (3, 3),strides=[2,2], kernel_initializer='he_uniform', padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Conv2D(256, (3, 3),strides=[2,2], kernel_initializer='he_uniform', padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    img = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)\n",
    "\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 64, 64, 3)         6774915   \n",
      "_________________________________________________________________\n",
      "model_2 (Model)              (None, 1)                 394433    \n",
      "=================================================================\n",
      "Total params: 7,169,348\n",
      "Trainable params: 7,166,980\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_gan():\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "gan = get_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0002,0.5)\n",
    "discriminator.compile(loss='binary_crossentropy', \n",
    "                                   optimizer=optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "discriminator.trainable = False\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def save_images(epoch):\n",
    "        noise = np.random.normal(0, 1, [100, 100])\n",
    "        image_array = np.empty([25, IMAGE_SIZE, IMAGE_SIZE,3])\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        image_count = 0\n",
    "        for i in range(5):\n",
    "                image_array[i] = gen_imgs[i]\n",
    "                im = np.asarray(image_array[i] * 255)\n",
    "                cv2.imwrite(RESULT_IMAGES_PATH + \"image_%d.png\" % (epoch + i) ,im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_loss_acc = []\n",
    "gan_loss_acc = []\n",
    "\n",
    "def train_gan():\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        # Initialize loss and acc for the discriminator / generator\n",
    "        d_loss_acc = [0, 0]\n",
    "        g_loss_acc = [0, 0]\n",
    "        # Create the nose input of shape batch_size, 100\n",
    "        noise = np.random.normal(0, 1, [BATCH_SIZE, 100])\n",
    "        # Create fake images using the generator\n",
    "        fake_images = generator.predict(noise)\n",
    "        # Create the coresponding output for fake images \n",
    "        fake_output = np.full((BATCH_SIZE, 1), 0)\n",
    "        # Index of 64 real real images\n",
    "        indexes = np.random.randint(0, len(os.listdir(TRAINING_IMAGES_PATH)), 64)\n",
    "        # Get a batch of real images\n",
    "        real_images = TRAINING_DATA[indexes]\n",
    "        # Output for the real image is 0.9 (https://machinelearningmastery.com/how-to-train-stable-generative-adversarial-networks/)\n",
    "        real_output = np.full((BATCH_SIZE, 1), 0.9)\n",
    "        # Train discrimnator on the real and fake images\n",
    "        d_loss_acc = np.add(d_loss_acc, discriminator.train_on_batch(fake_images, fake_output))\n",
    "        d_loss_acc = np.add(d_loss_acc, discriminator.train_on_batch(real_images, real_output))\n",
    "        d_loss_acc = d_loss_acc * 0.5\n",
    "        # Input data for training the generator\n",
    "        noise = np.random.normal(0,1, [BATCH_SIZE, 100])\n",
    "        g_loss_acc = np.add(g_loss_acc, gan.train_on_batch(noise,np.full((BATCH_SIZE, 1), 1)))\n",
    "        if i % 1000 == 0 and i != 0:\n",
    "            discriminator.save(RESULT_IMAGES_PATH + 'traffic_discriminator.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "            generator.save(RESULT_IMAGES_PATH + 'traffic_generator.h5')\n",
    "            print(d_loss_acc)\n",
    "            print(g_loss_acc)\n",
    "            discriminator_loss_acc.append(d_loss_acc)\n",
    "            gan_loss_acc.append(g_loss_acc)\n",
    "            save_images(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Cordu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[0.96640664 0.2421875 ]\n",
      "[1.14441466 0.15625   ]\n",
      "[0.58241394 0.453125  ]\n",
      "[0.80984199 0.421875  ]\n",
      "[0.7331959 0.34375  ]\n",
      "[0.81671774 0.390625  ]\n",
      "[0.69146562 0.421875  ]\n",
      "[0.92894346 0.171875  ]\n",
      "[0.6967504 0.4140625]\n",
      "[0.9367097 0.171875 ]\n",
      "[0.62292331 0.421875  ]\n",
      "[0.94000679 0.234375  ]\n",
      "[0.68659562 0.3515625 ]\n",
      "[0.98249054 0.21875   ]\n",
      "[0.61086392 0.40625   ]\n",
      "[0.90135455 0.3125    ]\n",
      "[0.71450886 0.3359375 ]\n",
      "[0.9439339 0.1875   ]\n",
      "[0.64077556 0.3828125 ]\n",
      "[0.94196558 0.21875   ]\n",
      "[0.64401525 0.375     ]\n",
      "[1.05308914 0.171875  ]\n",
      "[0.68103746 0.3046875 ]\n",
      "[0.95475292 0.25      ]\n",
      "[0.61684884 0.4140625 ]\n",
      "[1.13159728 0.140625  ]\n",
      "[0.53857481 0.4453125 ]\n",
      "[1.2212323 0.15625  ]\n",
      "[0.67967033 0.3828125 ]\n",
      "[1.17829633 0.125     ]\n",
      "[0.61900482 0.3671875 ]\n",
      "[1.24732816 0.15625   ]\n",
      "[0.54618534 0.3671875 ]\n",
      "[1.24631405 0.125     ]\n",
      "[0.60662818 0.375     ]\n",
      "[1.07266212 0.21875   ]\n",
      "[0.53533143 0.3984375 ]\n",
      "[1.49974072 0.09375   ]\n",
      "[0.49957418 0.375     ]\n",
      "[1.4510082 0.15625  ]\n",
      "[0.52078661 0.4765625 ]\n",
      "[1.27044356 0.203125  ]\n",
      "[0.42106338 0.4453125 ]\n",
      "[1.70980668 0.09375   ]\n",
      "[0.40096885 0.46875   ]\n",
      "[1.64961696 0.140625  ]\n",
      "[0.29359999 0.484375  ]\n",
      "[2.25106096 0.046875  ]\n",
      "[0.25351551 0.5       ]\n",
      "[2.84495497 0.        ]\n",
      "[0.45903248 0.40625   ]\n",
      "[2.83988714 0.015625  ]\n",
      "[0.27219779 0.5       ]\n",
      "[1.94136655 0.0625    ]\n",
      "[0.24871556 0.5       ]\n",
      "[2.79525065 0.03125   ]\n",
      "[0.36707865 0.484375  ]\n",
      "[3.39207149 0.        ]\n",
      "[0.2539216 0.4921875]\n",
      "[2.82306957 0.078125  ]\n",
      "[0.30362666 0.4921875 ]\n",
      "[4.18598652 0.        ]\n",
      "[0.25550396 0.4921875 ]\n",
      "[2.37627983 0.046875  ]\n",
      "[0.28225123 0.4921875 ]\n",
      "[3.28800964 0.015625  ]\n",
      "[0.26272587 0.5       ]\n",
      "[2.84258366 0.03125   ]\n",
      "[0.27599172 0.4921875 ]\n",
      "[2.59793663 0.015625  ]\n",
      "[0.27876592 0.5       ]\n",
      "[2.15438151 0.015625  ]\n",
      "[0.28136812 0.4921875 ]\n",
      "[3.65839458 0.        ]\n",
      "[0.26663914 0.4765625 ]\n",
      "[3.35127974 0.        ]\n",
      "[0.24650177 0.4921875 ]\n",
      "[3.85247016 0.        ]\n",
      "[0.31273497 0.46875   ]\n",
      "[4.16106415 0.        ]\n",
      "[0.29516065 0.484375  ]\n",
      "[3.64100599 0.        ]\n",
      "[0.26715101 0.5       ]\n",
      "[3.31436396 0.015625  ]\n",
      "[0.23810111 0.5       ]\n",
      "[4.03130627 0.        ]\n",
      "[0.24115101 0.5       ]\n",
      "[3.77350926 0.        ]\n",
      "[0.39602401 0.5       ]\n",
      "[3.13808012 0.        ]\n",
      "[0.26672682 0.5       ]\n",
      "[4.33479214 0.        ]\n",
      "[0.24117904 0.5       ]\n",
      "[3.68007493 0.        ]\n",
      "[0.22544043 0.5       ]\n",
      "[4.07000446 0.        ]\n",
      "[0.27062573 0.5       ]\n",
      "[3.40056086 0.        ]\n"
     ]
    }
   ],
   "source": [
    "train_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
